# Databricks Configuration
# Copy this file to .env and fill in your actual values

# Required: Your Databricks access token
DATABRICKS_TOKEN=your_databricks_token_here

# Optional: Override default hostname (default: samsara-dev-us-west-2.cloud.databricks.com)
# DATABRICKS_HOST=samsara-dev-us-west-2.cloud.databricks.com

# Optional: Override default warehouse path (for SQL fallback)
# DATABRICKS_HTTP_PATH=/sql/1.0/warehouses/9fb6a34db2b0bbde

# Required for PySpark: Your Databricks cluster ID
DATABRICKS_CLUSTER_ID=0809-193945-fon8dc5v

# Optional: Override default warehouse ID (for SQL fallback)
# DATABRICKS_WAREHOUSE_ID=9fb6a34db2b0bbde

# Execution Modes (in order of preference):
# 1. PySpark DataFrames in Databricks serverless cluster (preferred)
# 2. SQL queries in Databricks serverless cluster (fallback)
# 3. Local simulation (no credentials)

# How to get your Databricks token:
# 1. Go to your Databricks workspace
# 2. Click on your username in the top right
# 3. Go to "User Settings"
# 4. Go to "Access Tokens" tab
# 5. Click "Generate New Token"
# 6. Copy the token and paste it above

# Note: The notebook will automatically try PySpark first, then SQL, then simulation
